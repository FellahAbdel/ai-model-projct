{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Présentation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [],
   "source": [
    "# Exo 1 - Préparation des données \n",
    "\n",
    "# importation des données\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "# import du fichier\n",
    "data = pd.read_csv(\"synthetic.csv\")\n",
    "\n",
    "# Visualisation des données\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Nombre de colonnes (attributs) dans le DataFrame\n",
    "num_attributes = data.shape[1]\n",
    "\n",
    "# Afficher le nombre d'attributs\n",
    "print(f\"Le nombre d'attributs dans le fichier est : {num_attributes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type de données et valeurs manquantes\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoir le nombre d'attributs dans le modèle\n",
    "print(data.columns)\n",
    "# 14 attributs dans le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les classes uniques dans la colonne 'Class'\n",
    "classes_uniques = data['Class'].unique()\n",
    "\n",
    "# Nombre de classes différentes\n",
    "num_classes = len(classes_uniques)\n",
    "\n",
    "# Afficher le nombre de classes différentes\n",
    "print(f\"Le nombre de classes différentes dans les données est : {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combien d'instances compte chaque classe?\n",
    "nbr_instances = data['Class'].value_counts()\n",
    "print(nbr_instances)\n",
    "\n",
    "# Sortie \n",
    "# Class\n",
    "# 1    908\n",
    "# 0    674\n",
    "# 2    472\n",
    "# 3    244\n",
    "# Name: count, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les données sont-elles linéairement séparables ?\n",
    "Non, si on observe le schéma 1 on voit que les données ne le sont pas.\n",
    "De plus si l'on choisit de les ranger par classe , on peut s'apercevoir que \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # import biblio matplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(data['Attr_A'], data['Attr_B'], c=data['Class'], alpha=0.5, cmap='viridis')\n",
    "plt.xlabel('Attribut 1')\n",
    "plt.ylabel('Attribut 2')\n",
    "plt.title('Scatter Plot des attributs par classe')\n",
    "plt.colorbar(label='Classe')\n",
    "plt.show()\n",
    "\n",
    "# On peut voir clairement que ce n'est pas divisible linéairement à l'état brut\n",
    "# je pense que use image est vraiment mieux\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 et 6 (voir compte-rendu.md) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Mise en oeuvre des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisir un attribut à analyser, par exemple 'Attr_A'\n",
    "attribute = 'Attr_A'\n",
    "\n",
    "\n",
    "# Calculer les quartiles pour l'attribut choisi\n",
    "quartiles = data[attribute].quantile([0.25, 0.5, 0.75])\n",
    "\n",
    "# Sort the attribute values and print them\n",
    "sorted_attribute = data[attribute].sort_values()\n",
    "print(sorted_attribute)\n",
    "print(quartiles)\n",
    "# Afficher les quartiles\n",
    "print(f\"Quartile 1 (Q1) de l'attribut '{attribute}': {quartiles[0.25]}\")\n",
    "print(f\"Médiane (Q2) de l'attribut '{attribute}': {quartiles[0.5]}\")\n",
    "print(f\"Quartile 3 (Q3) de l'attribut '{attribute}': {quartiles[0.75]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2 : Mise en oeuvre des modèles.\n",
    "\n",
    "# Arbre de décision \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arbre de décision\n",
    "\n",
    "# Calcul de l'entropie\n",
    "\n",
    "\"\"\"\n",
    "L'entropie est une mesure de l'incertitude associée à une variable aléatoire.\n",
    "\"\"\"\n",
    "\n",
    "def entropie(dataframe , attribut_cible):  \n",
    "    # Calcul de la probabilité de chaque classe\n",
    "    compte_classe = dataframe[attribut_cible].value_counts()\n",
    "    #print(compte_classe)\n",
    "    proba = compte_classe / compte_classe.sum()\n",
    "    #print(proba) \n",
    "    # Calcul de l'entropie\n",
    "    entropie = - (proba * np.log2(proba+ np.finfo(float).eps)).sum() # éviter log2(0)\n",
    "    return entropie\n",
    "\n",
    "# Test de la fonction\n",
    "print(entropie(data, 'Attr_A'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.166163082646115\n",
    "11.166163082645376\n",
    "\n",
    "11.166163082646115\n",
    "11.166163082645376\n",
    "\n",
    "11.166163082646115\n",
    "11.166163082645376\n",
    "\n",
    "1.8608867211835993\n",
    "1.860886721183598"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Fonction pour calculer tous les quartiles d'un attribut donné\n",
    "def calculate_quartiles(data, attribute):\n",
    "    return data[attribute].quantile([0.25, 0.5, 0.75])\n",
    "\n",
    "# Test de la fonction sur le DataFrame chargé\n",
    "\n",
    "print(calculate_quartiles(data, 'Attr_A'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by=\"Attr_C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()\n",
    "sorted = data.sort_values(by=\"Attr_A\")\n",
    "print(len(sorted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui calcule le gain d'une partition\n",
    "def gain_information(dataframe, attribut_cible, attribut_test):\n",
    "    # Initial entropy of the target attribute\n",
    "    entropie_initiale = entropie(dataframe, attribut_cible)\n",
    "\n",
    "    # The gain, split_value and partitions initialized\n",
    "    max_gain = 0\n",
    "    best_split_value = None\n",
    "    best_partitions = None\n",
    "\n",
    "    # Sorting data by the attribute to test\n",
    "    sorted_data = dataframe.sort_values(by=attribut_test)\n",
    "\n",
    "    # Unique values of the attribute to test, considering quartiles to reduce complexity\n",
    "    unique_values = calculate_quartiles(sorted_data, attribut_test).to_list()\n",
    "    print(\"unique values\", unique_values);\n",
    "\n",
    "    # Adding the min and max values to cover the entire range of the attribute\n",
    "    unique_values = [sorted_data[attribut_test].min()] + \\\n",
    "        unique_values + [sorted_data[attribut_test].max()]\n",
    "    \n",
    "    print(f\"unique values after {unique_values}\");\n",
    "\n",
    "    # Iterating through the sorted unique values to find the best split\n",
    "    for split_value in unique_values:\n",
    "        # Partitioning the data based on the split value\n",
    "        lower_partition = sorted_data[sorted_data[attribut_test] < split_value]\n",
    "        upper_partition = sorted_data[sorted_data[attribut_test]\n",
    "                                      >= split_value]\n",
    "\n",
    "        # Calculating the weighted entropy for the partitions\n",
    "        # Row counts.\n",
    "        total_instances = len(sorted_data)\n",
    "        lower_weight = len(lower_partition) / total_instances\n",
    "        upper_weight = len(upper_partition) / total_instances\n",
    "\n",
    "        # Computing the weighted_entropy \n",
    "        weighted_entropy = (lower_weight * entropie(lower_partition, attribut_cible)) + \\\n",
    "                           (upper_weight * entropie(upper_partition, attribut_cible))\n",
    "\n",
    "        # Information gain for the current split\n",
    "        current_gain = entropie_initiale - weighted_entropy\n",
    "\n",
    "        # If the current gain is greater than the max_gain, update max_gain and best_split_value\n",
    "        if current_gain > max_gain:\n",
    "            max_gain = current_gain\n",
    "            best_split_value = split_value\n",
    "            best_partitions = (lower_partition, upper_partition)\n",
    "\n",
    "    # Returning the attribute, gain, split_value, and partitions as a tuple\n",
    "    return attribut_test, max_gain, best_split_value, best_partitions\n",
    "\n",
    "\n",
    "# Testing the function with an example attribute\n",
    "# Let's use 'Attr_A' as the attribute to test and 'Class' as the target\n",
    "test_gain_info = gain_information(data, 'Class', 'Attr_C')\n",
    "test_gain_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui reçoit un dataframe et retourne\n",
    "def func(attribut):\n",
    "    data_sorted = data.sort_values(by= attribut) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
