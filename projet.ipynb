{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Présentation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "dotnet_interactive": {
     "language": "csharp"
    },
    "polyglot_notebook": {
     "kernelName": "csharp"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Attr_A     Attr_B       Attr_C      Attr_D      Attr_E       Attr_F  \\\n",
      "0  12.478064  14.784992  1247.541877  100.962061   52.462177  1089.398211   \n",
      "1   8.264345   8.854181  1389.686814   99.526529   65.106526  1186.523399   \n",
      "2   9.875571  13.292442   779.077401  123.993772  104.699796  1201.722480   \n",
      "3   9.207661   9.346913   965.468523   89.176009  102.628284   743.913507   \n",
      "4   8.863842  12.542969  1096.386230  106.595385  131.813380   883.059615   \n",
      "\n",
      "      Attr_G     Attr_H     Attr_I      Attr_J       Attr_K     Attr_L  \\\n",
      "0  10.575834   8.375407  10.288159  110.746551   994.367610   9.069350   \n",
      "1   9.500485  10.088058   9.371983   78.210274   943.089589   9.988919   \n",
      "2   9.545266  14.266238   9.703551   86.252483  1082.989190  10.084217   \n",
      "3   9.777953  11.613946   8.912059   96.727873   812.800511   8.621781   \n",
      "4  10.092974  13.556029  11.649982   21.566576   971.083175  10.072271   \n",
      "\n",
      "        Attr_M      Attr_N  Class  \n",
      "0  1027.953917  109.672758      1  \n",
      "1  1120.317724   83.498764      3  \n",
      "2   970.953682   93.557046      2  \n",
      "3   947.207195  120.890054      3  \n",
      "4  1007.583900  149.511979      2  \n"
     ]
    }
   ],
   "source": [
    "# Exo 1 - Préparation des données \n",
    "\n",
    "# importation des données\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "# import du fichier\n",
    "data = pd.read_csv(\"synthetic.csv\")\n",
    "\n",
    "# Visualisation des données\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Nombre de colonnes (attributs) dans le DataFrame\n",
    "num_attributes = data.shape[1]\n",
    "\n",
    "# Afficher le nombre d'attributs\n",
    "print(f\"Le nombre d'attributs dans le fichier est : {num_attributes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Type de données et valeurs manquantes\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoir le nombre d'attributs dans le modèle\n",
    "print(data.columns)\n",
    "# 14 attributs dans le modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenir les classes uniques dans la colonne 'Class'\n",
    "classes_uniques = data['Class'].unique()\n",
    "\n",
    "# Nombre de classes différentes\n",
    "num_classes = len(classes_uniques)\n",
    "\n",
    "# Afficher le nombre de classes différentes\n",
    "print(f\"Le nombre de classes différentes dans les données est : {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combien d'instances compte chaque classe?\n",
    "nbr_instances = data['Class'].value_counts()\n",
    "print(nbr_instances)\n",
    "\n",
    "# Sortie \n",
    "# Class\n",
    "# 1    908\n",
    "# 0    674\n",
    "# 2    472\n",
    "# 3    244\n",
    "# Name: count, dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les données sont-elles linéairement séparables ?\n",
    "Non, si on observe le schéma 1 on voit que les données ne le sont pas.\n",
    "De plus si l'on choisit de les ranger par classe , on peut s'apercevoir que \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt # import biblio matplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(data['Attr_A'], data['Attr_B'], c=data['Class'], alpha=0.5, cmap='viridis')\n",
    "plt.xlabel('Attribut 1')\n",
    "plt.ylabel('Attribut 2')\n",
    "plt.title('Scatter Plot des attributs par classe')\n",
    "plt.colorbar(label='Classe')\n",
    "plt.show()\n",
    "\n",
    "# On peut voir clairement que ce n'est pas divisible linéairement à l'état brut\n",
    "# je pense que use image est vraiment mieux\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 et 6 (voir compte-rendu.md) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Mise en oeuvre des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisir un attribut à analyser, par exemple 'Attr_A'\n",
    "attribute = 'Attr_A'\n",
    "\n",
    "\n",
    "# Calculer les quartiles pour l'attribut choisi\n",
    "quartiles = data[attribute].quantile([0.25, 0.5, 0.75])\n",
    "\n",
    "# Sort the attribute values and print them\n",
    "sorted_attribute = data[attribute].sort_values()\n",
    "print(sorted_attribute)\n",
    "print(quartiles)\n",
    "# Afficher les quartiles\n",
    "print(f\"Quartile 1 (Q1) de l'attribut '{attribute}': {quartiles[0.25]}\")\n",
    "print(f\"Médiane (Q2) de l'attribut '{attribute}': {quartiles[0.5]}\")\n",
    "print(f\"Quartile 3 (Q3) de l'attribut '{attribute}': {quartiles[0.75]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie 2 : Mise en oeuvre des modèles.\n",
    "\n",
    "# Arbre de décision \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.166163082645376\n"
     ]
    }
   ],
   "source": [
    "# Arbre de décision\n",
    "\n",
    "# Calcul de l'entropie\n",
    "\n",
    "\"\"\"\n",
    "L'entropie est une mesure de l'incertitude associée à une variable aléatoire.\n",
    "\"\"\"\n",
    "\n",
    "def entropie(dataframe , attribut_cible):  \n",
    "    # Calcul de la probabilité de chaque classe\n",
    "    compte_classe = dataframe[attribut_cible].value_counts()\n",
    "    #print(compte_classe)\n",
    "    proba = compte_classe / compte_classe.sum()\n",
    "    #print(proba) \n",
    "    # Calcul de l'entropie\n",
    "    entropie = - (proba * np.log2(proba+ np.finfo(float).eps)).sum() # éviter log2(0)\n",
    "    return entropie\n",
    "\n",
    "# Test de la fonction\n",
    "print(entropie(data, 'Attr_A'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.166163082646115\n",
    "11.166163082645376\n",
    "\n",
    "11.166163082646115\n",
    "11.166163082645376\n",
    "\n",
    "11.166163082646115\n",
    "11.166163082645376\n",
    "\n",
    "1.8608867211835993\n",
    "1.860886721183598"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Fonction pour calculer tous les quartiles d'un attribut donné\n",
    "def calculate_quartiles(data, attribute):\n",
    "    quartiles =data[attribute].quantile([0.25, 0.5, 0.75])\n",
    "    return quartiles\n",
    "\n",
    "# Test de la fonction sur le DataFrame chargé\n",
    "\n",
    "print(calculate_quartiles(data, 'Attr_A'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by=\"Attr_C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.head()\n",
    "sorted = data.sort_values(by=\"Attr_A\")\n",
    "print(len(sorted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gain_information(dataframe, attribut_cible, attribut_test):\n",
    "    \"\"\"\n",
    "    Calculate the information gain from splitting the data based on a test attribute.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): The DataFrame containing the data to partition.\n",
    "    attribut_cible (str): The target attribute we want to predict.\n",
    "    attribut_test (str): The attribute whose gain we want to calculate.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - attribut_test (str): The test attribute.\n",
    "        - max_gain (float): The maximum information gain obtained.\n",
    "        - best_split_value (float): The split value that provides the best gain.\n",
    "        - best_partitions (tuple): A tuple containing two DataFrames representing the lower and upper partitions\n",
    "          resulting from the best split.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initial entropy of the target attribute\n",
    "    entropie_initiale = entropie(dataframe, attribut_cible)\n",
    "\n",
    "    # The gain, split_value and partitions initialized\n",
    "    max_gain = 0\n",
    "    best_split_value = None\n",
    "    best_partitions = None\n",
    "\n",
    "    # Check for no unique values in the attribute being tested\n",
    "    if len(dataframe[attribut_test].unique()) <= 1:\n",
    "        return None\n",
    "\n",
    "    # Sorting data by the attribute to test\n",
    "    sorted_data = dataframe.sort_values(by=attribut_test)\n",
    "\n",
    "    # Unique values of the attribute to test, considering quartiles to reduce complexity\n",
    "    quartiles = calculate_quartiles(sorted_data, attribut_test).to_list()\n",
    "\n",
    "    # Adding the min and max values to cover the entire range of the attribute\n",
    "    # quartiles = [sorted_data[attribut_test].min()] + quartiles + \\\n",
    "    #     [sorted_data[attribut_test].max()]\n",
    "    # Voir si je n'enlève pas min et max valeur\n",
    "\n",
    "    # Iterating through the sorted unique values to find the best split\n",
    "    for split_value in quartiles:\n",
    "        # Partitioning the data based on the split value\n",
    "        lower_partition = sorted_data[sorted_data[attribut_test] < split_value]\n",
    "        upper_partition = sorted_data[sorted_data[attribut_test]\n",
    "                                      >= split_value]\n",
    "\n",
    "        # Calculating the weighted entropy for the partitions\n",
    "        # Row counts.\n",
    "        total_instances = len(sorted_data)\n",
    "        lower_weight = len(lower_partition) / total_instances\n",
    "        upper_weight = len(upper_partition) / total_instances\n",
    "\n",
    "        # Computing the weighted_entropy\n",
    "        weighted_entropy = (lower_weight * entropie(lower_partition, attribut_cible)) + \\\n",
    "                           (upper_weight * entropie(upper_partition, attribut_cible))\n",
    "\n",
    "        # Information gain for the current split\n",
    "        current_gain = entropie_initiale - weighted_entropy\n",
    "\n",
    "        # If the current gain is greater than the max_gain, update max_gain and best_split_value\n",
    "        if current_gain > max_gain:\n",
    "            max_gain = current_gain\n",
    "            best_split_value = split_value\n",
    "            best_partitions = (lower_partition, upper_partition)\n",
    "\n",
    "    # Returning the attribute, gain, split_value, and partitions as a tuple\n",
    "    return attribut_test, max_gain, best_split_value, best_partitions\n",
    "\n",
    "\n",
    "# Testing the function with an example attribute\n",
    "# Let's use 'Attr_A' as the attribute to test and 'Class' as the target\n",
    "test_gain_info = gain_information(data, 'Class', 'Attr_H')\n",
    "test_gain_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quartiles_opti(data, attribute):\n",
    "    quartiles =data[attribute].quantile([0.25, 0.5, 0.75])\n",
    "    return quartiles.tolist()\n",
    "\n",
    "def check_variance(dataframe, attribut_test, threshold=0.01):\n",
    "    return dataframe[attribut_test].var() >= threshold\n",
    "\n",
    "\n",
    "def gain_information_optimized(dataframe, attribut_cible, attribut_test):\n",
    "    # Si l'attribut a très peu de valeurs uniques, éviter de l'utiliser pour le split\n",
    "    if dataframe[attribut_test].nunique() <= 1:\n",
    "        return attribut_test, 0, None, None\n",
    "\n",
    "    # vérifier variance     \n",
    "    if not check_variance(dataframe, attribut_test):\n",
    "        return attribut_test, 0, None, None\n",
    "\n",
    "\n",
    "    # Tri des données par l'attribut à tester \n",
    "    sorted_data = dataframe.sort_values(by=attribut_test)\n",
    "    total_count = len(sorted_data)\n",
    "    entropie_initiale = entropie(dataframe, attribut_cible)\n",
    "\n",
    "    max_gain = 0\n",
    "    best_split_value = None\n",
    "    best_partitions = None\n",
    "\n",
    "    # Calcul des quartiles\n",
    "    quartiles = calculate_quartiles_opti(sorted_data, attribut_test)\n",
    "    thresholds = quartiles \n",
    "\n",
    "    # Initialisation des partitions\n",
    "    lower_partition = pd.DataFrame(columns=sorted_data.columns)\n",
    "    upper_partition = sorted_data.copy()\n",
    "\n",
    "    previous_threshold = thresholds[0]\n",
    "\n",
    "    for threshold in thresholds[1:]:\n",
    "        # Déplacer les données de upper à lower basées sur le seuil actuel\n",
    "        mask = (upper_partition[attribut_test] < threshold)\n",
    "        moving_data = upper_partition[mask]\n",
    "        lower_partition = pd.concat([lower_partition, moving_data])\n",
    "        upper_partition = upper_partition[~mask]\n",
    "\n",
    "        # Vérifier si les partitions sont vides\n",
    "        if lower_partition.empty or upper_partition.empty:\n",
    "            continue\n",
    "\n",
    "        # Calcul de l'entropie pondérée pour les partitions actuelles\n",
    "        lower_weight = len(lower_partition) / total_count\n",
    "        upper_weight = len(upper_partition) / total_count\n",
    "\n",
    "        weighted_entropy = (lower_weight * entropie(lower_partition, attribut_cible) +\n",
    "                            upper_weight * entropie(upper_partition, attribut_cible))\n",
    "        current_gain = entropie_initiale - weighted_entropy\n",
    "\n",
    "        # Mise à jour du meilleur gain si nécessaire\n",
    "        if current_gain > max_gain:\n",
    "            max_gain = current_gain\n",
    "            best_split_value = threshold\n",
    "            best_partitions = (lower_partition.copy(), upper_partition.copy())\n",
    "\n",
    "    return attribut_test, max_gain, best_split_value, best_partitions\n",
    "\n",
    "\n",
    "\n",
    "# Testing the function with an example attribute\n",
    "# Let's use 'Attr_A' as the attribute to test and 'Class' as the target\n",
    "test_gain_info = gain_information_optimized(data, 'Class', 'Attr_H')\n",
    "test_gain_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_gain(dataframe, attribut_cible):\n",
    "    \"\"\"\n",
    "    Calculate the best information gain and corresponding split in a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): The input data as a pandas DataFrame.\n",
    "    attribut_cible (str): The target attribute that we want to predict (e.g. 'Class').\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing the following elements:\n",
    "        - best_attribute (str): The attribute that yields the best information gain.\n",
    "        - best_gain (float): The highest information gain observed.\n",
    "        - best_split_value (float): The split value that produces the best gain.\n",
    "        - best_partitions (tuple): A tuple containing the two partitions resulting from the best split.\n",
    "    \"\"\"\n",
    "    # Initialize variables to track the best gain and the associated attribute\n",
    "    best_gain = 0\n",
    "    best_attribute = None\n",
    "    best_split_value = None\n",
    "    best_partitions = None\n",
    "\n",
    "    # Iterate over all the attributes in the DataFrame, except the target attribute\n",
    "    for test_attribute in dataframe.columns:\n",
    "        if test_attribute == attribut_cible:\n",
    "            continue  # Skip the target attribute\n",
    "\n",
    "        # Calculate the information gain for the current attribute\n",
    "        # result = gain_information(dataframe, attribut_cible, test_attribute)\n",
    "        \n",
    "        # optimized version\n",
    "        result = gain_information(dataframe, attribut_cible, test_attribute)\n",
    "        \n",
    "        # If the result is None, skip to the next attribute\n",
    "        if result is None:\n",
    "            continue\n",
    "\n",
    "        # Unpack the result from gain_information\n",
    "        _, current_gain, split_value, partitions = result\n",
    "\n",
    "        # Update the variables if the current gain is higher than the best gain\n",
    "        if current_gain > best_gain:\n",
    "            best_gain = current_gain\n",
    "            best_attribute = test_attribute\n",
    "            best_split_value = split_value\n",
    "            best_partitions = partitions\n",
    "\n",
    "    # Return the best attribute, gain, split value, and partitions\n",
    "    return best_attribute, best_gain, best_split_value, best_partitions\n",
    "\n",
    "\n",
    "find_best_gain(data, 'Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(dataframe, attribut_cible, test_size=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Splits the dataframe into training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "    dataframe (pd.DataFrame): The DataFrame containing the data to split.\n",
    "    attribut_cible (str): The target attribute we want to predict. e.g (\"Class\")\n",
    "    test_size (float): The proportion of the data to include in the test split. Default is 0.2.\n",
    "    random_state (int): Controls the shuffling applied to the data before applying the split. Default is 42.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - X_train (pd.DataFrame): The training features.\n",
    "        - X_test (pd.DataFrame): The testing features.\n",
    "        - y_train (pd.Series): The training target attribute.\n",
    "        - y_test (pd.Series): The testing target attribute.\n",
    "    \"\"\"\n",
    "    # Separate features and target attribute\n",
    "    X = dataframe.drop(columns=[attribut_cible])\n",
    "    y = dataframe[attribut_cible]\n",
    "    \n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test =  split_data(data, \"Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    def __init__(\n",
    "            self,\n",
    "            is_leaf,\n",
    "            attribute=None,\n",
    "            split_value=None,\n",
    "            left=None,\n",
    "            right=None,\n",
    "            prediction=None):\n",
    "        \"\"\"\n",
    "        Initialize a decision tree node.\n",
    "\n",
    "        Parameters:\n",
    "        is_leaf (bool): Whether the node is a leaf node.\n",
    "        attribute (str, optional): The attribute to split on if the node is not a leaf.\n",
    "        split_value (float, optional): The split value for the attribute if the node is not a leaf.\n",
    "        left (DecisionNode, optional): The left child node.\n",
    "        right (DecisionNode, optional): The right child node.\n",
    "        value (object, optional): The target value if the node is a leaf.\n",
    "        \"\"\"\n",
    "        self.is_leaf = is_leaf\n",
    "        self.attribute = attribute\n",
    "        self.split_value = split_value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.prediction = prediction\n",
    "\n",
    "    def _is_leaf(self):\n",
    "        return self.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \"\"\"\n",
    "    Represents a decision tree.\n",
    "\n",
    "    Attributes:\n",
    "    max_depth (int): The maximum depth of the tree.\n",
    "    tree (DecisionNode): The root node of the tree.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, max_depth=8):\n",
    "        \"\"\"\n",
    "        Initialize the decision tree.\n",
    "\n",
    "        Parameters:\n",
    "        max_depth (int, optional): The maximum depth of the tree. Default is 8.\n",
    "        \"\"\"\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def _build_tree(self, data, target_attribute, depth=0):\n",
    "        \"\"\"\n",
    "        Recursively build the decision tree.\n",
    "\n",
    "        Parameters:\n",
    "        data (pd.DataFrame): The input data as a pandas DataFrame.\n",
    "        target_attribute (str): The target attribute that we want to predict.\n",
    "        depth (int): The current depth of the tree.\n",
    "\n",
    "        Returns:\n",
    "        DecisionNode: The root node of the decision tree.\n",
    "        \"\"\"\n",
    "        # Check stopping conditions: maximum depth or pure leaf\n",
    "        if depth >= self.max_depth:\n",
    "            # Return a leaf node with the most frequent target value\n",
    "            prediction = data[target_attribute].mode()[0]\n",
    "            return DecisionNode(is_leaf=True, prediction=prediction)\n",
    "\n",
    "        # Check if the data is pure (all target values are the same)\n",
    "        if data[target_attribute].nunique() == 1:\n",
    "            # Return a leaf node with the unique target value\n",
    "            prediction = data[target_attribute].iloc[0]\n",
    "            return DecisionNode(is_leaf=True, prediction=prediction)\n",
    "\n",
    "        # Find the best attribute, gain, split value, and partitions using find_best_gain\n",
    "        best_attribute, best_gain, best_split_value, best_partitions = find_best_gain(\n",
    "            data, target_attribute)\n",
    "\n",
    "        # Check if no gain is found, return the most frequent target value as a leaf node\n",
    "        if best_attribute is None or best_gain <= 0:\n",
    "            prediction = data[target_attribute].mode()[0]\n",
    "            return DecisionNode(is_leaf=True, prediction=prediction)\n",
    "\n",
    "        # Create the decision node with the best attribute and split value\n",
    "        left_data, right_data = best_partitions\n",
    "        left_child = self._build_tree(left_data, target_attribute, depth + 1)\n",
    "        right_child = self._build_tree(right_data, target_attribute, depth + 1)\n",
    "\n",
    "        # Return the decision node with the children\n",
    "        return DecisionNode(\n",
    "            is_leaf=False,\n",
    "            attribute=best_attribute,\n",
    "            split_value=best_split_value,\n",
    "            left=left_child,\n",
    "            right=right_child\n",
    "        )\n",
    "\n",
    "    def fit(self, data, target_attribute):\n",
    "        \"\"\"\n",
    "        Build the decision tree based on the provided data and target attribute. e.g (\"Class\")\n",
    "        Parameters:\n",
    "        data (pd.DataFrame): The input data as a pandas DataFrame.\n",
    "        target_attribute (str): The target attribute that we want to predict.\n",
    "        \"\"\"\n",
    "        self.tree = self._build_tree(data, target_attribute)\n",
    "\n",
    "    def train(self, dataframe, target_attribute):\n",
    "        \"\"\"\n",
    "        Train the decision tree using the given data.\n",
    "\n",
    "        Parameters:\n",
    "        dataframe (pd.DataFrame): The DataFrame containing the training data.\n",
    "        target_attribute (str): The target attribute we want to predict.\n",
    "        \"\"\"\n",
    "        self.fit(dataframe, target_attribute)\n",
    "\n",
    "    def predict(self, data):\n",
    "        \"\"\"\n",
    "        Predict target attribute values for the given data using the decision tree.\n",
    "\n",
    "        Parameters:\n",
    "        data (pd.DataFrame): The data for which predictions are to be made.\n",
    "\n",
    "        Returns:\n",
    "        np.array: The predicted values of the target attribute.\n",
    "        \"\"\"\n",
    "        predictions = data.apply(self._predict_single, axis=1)\n",
    "        return predictions\n",
    "\n",
    "    def _predict_single(self, row):\n",
    "        \"\"\"\n",
    "        Predict the target attribute value for a single data point.\n",
    "\n",
    "        Parameters:\n",
    "        row (pd.Series): The data point as a pandas Series.\n",
    "\n",
    "        Returns:\n",
    "        object: The predicted value of the target attribute.\n",
    "        \"\"\"\n",
    "        node = self.tree\n",
    "\n",
    "        # Traverse the tree until a leaf node is reached\n",
    "        while not node.is_leaf:\n",
    "            attribute = node.attribute\n",
    "            split_value = node.split_value\n",
    "\n",
    "            if row[attribute] < split_value:\n",
    "                node = node.left\n",
    "            else:\n",
    "                node = node.right\n",
    "\n",
    "        # Return the value of the leaf node\n",
    "        return node.prediction\n",
    "\n",
    "    def print_tree(self, node=None, indent=\"\"):\n",
    "        \"\"\"\n",
    "        Print the decision tree in a human-readable way.\n",
    "\n",
    "        Parameters:\n",
    "        node (DecisionNode, optional): The current node to print. If not specified, starts with the root node.\n",
    "        indent (str): Indentation for nested levels in the tree.\n",
    "        \"\"\"\n",
    "        # If no node is specified, start with the root node\n",
    "        if node is None:\n",
    "            node = self.tree\n",
    "\n",
    "        # Check if the current node is a leaf node\n",
    "        if node._is_leaf():\n",
    "            print(f\"{indent}Leaf: Predict {node.prediction}\")\n",
    "        else:\n",
    "            # Print the split condition and value at the current node\n",
    "            print(f\"{indent}Node: {node.attribute} < {node.split_value}\")\n",
    "\n",
    "            # Recursively print the left and right children\n",
    "            print(f\"{indent}Left:\")\n",
    "            self.print_tree(node.left, indent + \"    \")\n",
    "\n",
    "            print(f\"{indent}Right:\")\n",
    "            self.print_tree(node.right, indent + \"    \" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class qui permet d'évaluer notre model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvaluationMetrics:\n",
    "    \"\"\"\n",
    "    Classe pour calculer les métriques d'évaluation.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def accuracy_score(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Calcule l'exactitude entre les valeurs réelles et prédites.\n",
    "        \n",
    "        Arguments:\n",
    "        y_true -- Les valeurs réelles (cibles).\n",
    "        y_pred -- Les valeurs prédites par le modèle.\n",
    "        \n",
    "        Retourne:\n",
    "        float -- L'exactitude.\n",
    "        \"\"\"\n",
    "        correct_predictions = sum(y_true == y_pred)\n",
    "        total_predictions = len(y_true)\n",
    "        return correct_predictions / total_predictions\n",
    "\n",
    "    @staticmethod\n",
    "    def precision_score(y_true, y_pred, positive_label):\n",
    "        \"\"\"\n",
    "        Calcule la précision pour une classe positive spécifiée.\n",
    "        \n",
    "        Arguments:\n",
    "        y_true -- Les valeurs réelles (cibles).\n",
    "        y_pred -- Les valeurs prédites par le modèle.\n",
    "        positive_label -- La classe positive pour laquelle calculer la précision.\n",
    "        \n",
    "        Retourne:\n",
    "        float -- La précision.\n",
    "        \"\"\"\n",
    "        true_positives = sum((y_true == positive_label) & (y_pred == positive_label))\n",
    "        predicted_positives = sum(y_pred == positive_label)\n",
    "        if predicted_positives == 0:\n",
    "            return 0.0\n",
    "        return true_positives / predicted_positives\n",
    "\n",
    "    @staticmethod\n",
    "    def recall_score(y_true, y_pred, positive_label):\n",
    "        \"\"\"\n",
    "        Calcule le rappel pour une classe positive spécifiée.\n",
    "        \n",
    "        Arguments:\n",
    "        y_true -- Les valeurs réelles (cibles).\n",
    "        y_pred -- Les valeurs prédites par le modèle.\n",
    "        positive_label -- La classe positive pour laquelle calculer le rappel.\n",
    "        \n",
    "        Retourne:\n",
    "        float -- Le rappel.\n",
    "        \"\"\"\n",
    "        true_positives = sum((y_true == positive_label) & (y_pred == positive_label))\n",
    "        actual_positives = sum(y_true == positive_label)\n",
    "        if actual_positives == 0:\n",
    "            return 0.0\n",
    "        return true_positives / actual_positives\n",
    "\n",
    "    @staticmethod\n",
    "    def f1_score(y_true, y_pred, positive_label):\n",
    "        \"\"\"\n",
    "        Calcule le score F1 pour une classe positive spécifiée.\n",
    "        \n",
    "        Arguments:\n",
    "        y_true -- Les valeurs réelles (cibles).\n",
    "        y_pred -- Les valeurs prédites par le modèle.\n",
    "        positive_label -- La classe positive pour laquelle calculer le score F1.\n",
    "        \n",
    "        Retourne:\n",
    "        float -- Le score F1.\n",
    "        \"\"\"\n",
    "        precision = EvaluationMetrics.precision_score(y_true, y_pred, positive_label)\n",
    "        recall = EvaluationMetrics.recall_score(y_true, y_pred, positive_label)\n",
    "        \n",
    "        if precision == 0 and recall == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return 2 * (precision * recall) / (precision + recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_decision_trees(X_train, y_train, X_test, y_test, depths):\n",
    "    \"\"\"\n",
    "    Train decision tree models with different maximum depths and evaluate their performance.\n",
    "\n",
    "    Args:\n",
    "        X_train: Training features (data).\n",
    "        y_train: Training target (labels).\n",
    "        X_test: Testing features (data).\n",
    "        y_test: Testing target (labels).\n",
    "        depths (list): List of maximum depths to test for decision trees.\n",
    "\n",
    "    Returns:\n",
    "        List of tuples containing the accuracy scores and corresponding models.\n",
    "        The list is sorted in descending order based on accuracy scores.\n",
    "    \"\"\"\n",
    "    # Combine features and labels for training and testing sets\n",
    "    train_data = pd.concat([X_train, y_train], axis=1)\n",
    "    test_data = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "    # List to store the models and their accuracy scores\n",
    "    models_and_scores = []\n",
    "\n",
    "    # Train and evaluate models with different maximum depths\n",
    "    for max_depth in depths:\n",
    "        # Create a decision tree classifier with the specified maximum depth\n",
    "        model = DecisionTree(max_depth=max_depth)\n",
    "        \n",
    "        # Train the model on the combined training set\n",
    "        model.train(train_data, y_train.name)  # Pass the name of the target attribute\n",
    "        \n",
    "        # Predict on the combined test set\n",
    "        y_pred = model.predict(test_data)\n",
    "        \n",
    "        # Calculate the accuracy of the model using the provided y_test\n",
    "        accuracy = EvaluationMetrics.accuracy_score(y_test, y_pred)\n",
    "        \n",
    "        # Append the accuracy score and model to the list\n",
    "        models_and_scores.append((accuracy, model))\n",
    "        \n",
    "        # Print the results for the current model\n",
    "        print(f\"Max Depth: {max_depth}, Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Sort the list of models and scores in descending order based on accuracy\n",
    "    models_and_scores.sort(key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    return models_and_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_attribute  = \"Class\"\n",
    "X_train, X_test, y_train, y_test = split_data(data, target_attribute)\n",
    "models_and_scores = train_and_evaluate_decision_trees(X_train, y_train, X_test, y_test, [3, 4, 5, 6, 7, 8])\n",
    "print(models_and_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two best models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = models_and_scores[0]\n",
    "second_best_model = models_and_scores[1]\n",
    "\n",
    "print(\"Best model\", best_model)\n",
    "print(\"Second Best model\", second_best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of DecisionNode and DecisionTree class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Define the target attribute\n",
    "target_attribute = \"Class\"\n",
    "\n",
    "# Split the data into training and testing sets using the split_data function\n",
    "X_train, X_test, y_train, y_test = split_data(data, target_attribute)\n",
    "\n",
    "# Instantiate the DecisionTree class\n",
    "decision_tree = DecisionTree(max_depth=8)\n",
    "evaluation_metric = EvaluationMetrics()\n",
    "\n",
    "# Train the decision tree using the training data\n",
    "decision_tree.train(pd.concat([X_train, y_train], axis=1), target_attribute)\n",
    "\n",
    "# Predict the target attribute for the testing data\n",
    "predictions = decision_tree.predict(pd.concat([X_test, y_test], axis=1))\n",
    "\n",
    "# Evaluate the model using accuracy, precision, recall, and F1-score\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "eval_accuracy = evaluation_metric.accuracy_score(y_test, predictions)\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "eval_precision = evaluation_metric.precision_score(y_test, predictions, positive_label=1)\n",
    "\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "eval_recall = evaluation_metric.recall_score(y_test, predictions, positive_label=1)\n",
    "\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "eval_f1 = evaluation_metric.f1_score(y_test, predictions, positive_label=1)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Eval Accuracy: {eval_accuracy:.2f}\")\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Eval Precision: {eval_precision:.2f}\")\n",
    "\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"Eval Recall: {eval_recall:.2f}\")\n",
    "\n",
    "print(f\"F1-score: {f1:.2f}\")\n",
    "print(f\"Eval F1-score: {eval_f1:.2f}\")\n",
    "\n",
    "decision_tree.print_tree()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Réseaux de neurones artificiels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Division des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def neural_split_data(data, target_attribute):\n",
    "\n",
    "    # Séparez les données et les labels afin de pouvoir séparer en jeu d'entrainement\n",
    "    # de test et de validation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.drop(columns=[target_attribute]),\n",
    "                                                        data[target_attribute], test_size=0.15, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15/0.85,\n",
    "                                                    random_state=42)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "#print (X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy Loss:  0.010199795719758053\n",
      "Debugging Entropy Calculation:\n",
      "Calculated Entropy: 1.556656707462822\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "# Cross Entropy function.\n",
    "def cross_entropy(y_pred, y_true):\n",
    " \n",
    "    # computing softmax values for predicted values\n",
    "    y_pred = softmax(y_pred)\n",
    "    loss = 0\n",
    "     \n",
    "    # Doing cross entropy Loss\n",
    "    for i in range(len(y_pred)):\n",
    " \n",
    "        # Here, the loss is computed using the\n",
    "        # above mathematical formulation.\n",
    "        loss = loss + (-1 * y_true[i]*np.log(y_pred[i]))\n",
    " \n",
    "    return loss\n",
    " \n",
    "# y_true: True Probability Distribution\n",
    "y_true = [1, 0, 0, 0, 0]\n",
    " \n",
    "# y_pred: Predicted values for each calss\n",
    "y_pred = [10, 5, 3, 1, 4]\n",
    "\n",
    "# Calling the cross_entropy function by passing\n",
    "# the suitable values\n",
    "cross_entropy_loss = cross_entropy(y_pred, y_true)\n",
    " \n",
    "print(\"Cross Entropy Loss: \", cross_entropy_loss)\n",
    "\n",
    "\n",
    "print(\"Debugging Entropy Calculation:\")\n",
    "debug_data = pd.DataFrame({\"Class\": [1, 1, 1, 0, 0, 2, 2]})\n",
    "print(f\"Calculated Entropy: {entropie(debug_data, 'Class')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Création de la classe \"NeuralNetwork\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (64,1608) and (14,1608) not aligned: 1608 (dim 1) != 14 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/marcolyantoine/Desktop/ia/projet.ipynb Cellule 40\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/marcolyantoine/Desktop/ia/projet.ipynb#X53sZmlsZQ%3D%3D?line=101'>102</a>\u001b[0m neural_network \u001b[39m=\u001b[39m NeuralNetwork(architecture, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/marcolyantoine/Desktop/ia/projet.ipynb#X53sZmlsZQ%3D%3D?line=103'>104</a>\u001b[0m \u001b[39m# Train the neural network using the training data\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/marcolyantoine/Desktop/ia/projet.ipynb#X53sZmlsZQ%3D%3D?line=104'>105</a>\u001b[0m neural_network\u001b[39m.\u001b[39mtrain(X_train, y_train, epochs\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, learning_rate\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/marcolyantoine/Desktop/ia/projet.ipynb#X53sZmlsZQ%3D%3D?line=106'>107</a>\u001b[0m \u001b[39m# Evaluate the neural network using the validation data\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/marcolyantoine/Desktop/ia/projet.ipynb#X53sZmlsZQ%3D%3D?line=107'>108</a>\u001b[0m validation_loss \u001b[39m=\u001b[39m neural_network\u001b[39m.\u001b[39mevaluate(X_val, y_val)\n",
      "\u001b[1;32m/Users/marcolyantoine/Desktop/ia/projet.ipynb Cellule 40\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/marcolyantoine/Desktop/ia/projet.ipynb#X53sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m, X, y, epochs\u001b[39m=\u001b[39m\u001b[39m1000\u001b[39m, learning_rate\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/marcolyantoine/Desktop/ia/projet.ipynb#X53sZmlsZQ%3D%3D?line=66'>67</a>\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/marcolyantoine/Desktop/ia/projet.ipynb#X53sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m         activations, weighted_inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward_propagation(X)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/marcolyantoine/Desktop/ia/projet.ipynb#X53sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m         gradients \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbackward_propagation(X, y, activations, weighted_inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/marcolyantoine/Desktop/ia/projet.ipynb#X53sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mupdate_parameters(gradients, learning_rate)\n",
      "\u001b[1;32m/Users/marcolyantoine/Desktop/ia/projet.ipynb Cellule 40\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/marcolyantoine/Desktop/ia/projet.ipynb#X53sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m weighted_inputs \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/marcolyantoine/Desktop/ia/projet.ipynb#X53sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights)):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/marcolyantoine/Desktop/ia/projet.ipynb#X53sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m     weighted_input \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdot(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights[i], activations[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbiases[i]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/marcolyantoine/Desktop/ia/projet.ipynb#X53sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m     weighted_inputs\u001b[39m.\u001b[39mappend(weighted_input)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/marcolyantoine/Desktop/ia/projet.ipynb#X53sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     activations\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation_function(weighted_input))\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (64,1608) and (14,1608) not aligned: 1608 (dim 1) != 14 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, architecture, activation='relu'):\n",
    "        self.architecture = architecture\n",
    "        self.activation = activation\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.initialize_parameters()\n",
    "\n",
    "    def initialize_parameters(self):\n",
    "        np.random.seed(42)\n",
    "        for i in range(1, len(self.architecture)):\n",
    "            if self.activation == 'relu':\n",
    "                # He initialization for ReLU\n",
    "                weight_matrix = np.random.randn(self.architecture[i], self.architecture[i - 1]) * np.sqrt(2. / self.architecture[i - 1])\n",
    "            else:\n",
    "                # Xavier initialization for other activations\n",
    "                weight_matrix = np.random.randn(self.architecture[i], self.architecture[i - 1]) * np.sqrt(1. / self.architecture[i - 1])\n",
    "            bias_vector = np.zeros((self.architecture[i], 1))\n",
    "            self.weights.append(weight_matrix)\n",
    "            self.biases.append(bias_vector)\n",
    "\n",
    "    def activation_function(self, x):\n",
    "        if self.activation == 'relu':\n",
    "            return np.maximum(0, x)\n",
    "        elif self.activation == 'tanh':\n",
    "            return np.tanh(x)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation function. Choose 'relu' or 'tanh'.\")\n",
    "\n",
    "    def activation_derivative(self, x):\n",
    "        if self.activation == 'relu':\n",
    "            return (x > 0).astype(float)\n",
    "        elif self.activation == 'tanh':\n",
    "            return 1 - np.tanh(x)**2\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported activation function for derivative. Choose 'relu' or 'tanh'.\")\n",
    "\n",
    "    def forward_propagation(self, X):\n",
    "        activations = [X.T]\n",
    "        weighted_inputs = []\n",
    "        for i in range(len(self.weights)):\n",
    "            weighted_input = np.dot(self.weights[i], activations[-1]) + self.biases[i]\n",
    "            weighted_inputs.append(weighted_input)\n",
    "            activations.append(self.activation_function(weighted_input))\n",
    "        return activations, weighted_inputs\n",
    "    \n",
    "\n",
    "\n",
    "    def backward_propagation(self, X, y, activations, weighted_inputs):\n",
    "        m = X.shape[1]\n",
    "        gradients = [np.zeros_like(w) for w in self.weights]\n",
    "        delta = activations[-1] - y\n",
    "        for i in range(m - 1, 0, -1):\n",
    "            gradients[i] = np.dot(delta, activations[i - 1].T) / m\n",
    "            delta = np.dot(self.weights[i].T, delta) * self.activation_derivative(weighted_inputs[i - 1])\n",
    "        gradients[0] = np.dot(delta, X.T) / m\n",
    "        return gradients\n",
    "    \n",
    "    def update_parameters(self, gradients, learning_rate):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= learning_rate * gradients[i]\n",
    "            self.biases[i] -= learning_rate * gradients[i]\n",
    "    \n",
    "    def train(self, X, y, epochs=1000, learning_rate=0.01):\n",
    "        for epoch in range(epochs):\n",
    "            activations, weighted_inputs = self.forward_propagation(X)\n",
    "            gradients = self.backward_propagation(X, y, activations, weighted_inputs)\n",
    "            self.update_parameters(gradients, learning_rate)\n",
    "            if epoch % 100 == 0:\n",
    "                loss = cross_entropy(activations[-1], y)\n",
    "                print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        activations, _ = self.forward_propagation(X)\n",
    "        return activations[-1]\n",
    "    \n",
    "    def evaluate(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        loss = cross_entropy(predictions, y)\n",
    "        return loss\n",
    "    \n",
    "    def print_parameters(self):\n",
    "        for i in range(len(self.weights)):\n",
    "            print(f\"Layer {i + 1}:\")\n",
    "            print(\"Weights:\")\n",
    "            print(self.weights[i])\n",
    "            print(\"Biases:\")\n",
    "            print(self.biases[i])\n",
    "\n",
    "# Define the target attribute\n",
    "target_attribute = \"Class\"\n",
    "\n",
    "# Split the data into training, validation, and testing sets using the neural_split_data function\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = neural_split_data(data, target_attribute)\n",
    "\n",
    "# Define the architecture of the neural network\n",
    "architecture = [X_train.shape[0], 64, 32, 4]\n",
    "\n",
    "# Instantiate the NeuralNetwork class\n",
    "neural_network = NeuralNetwork(architecture, activation='relu')\n",
    "\n",
    "# Train the neural network using the training data\n",
    "neural_network.train(X_train, y_train, epochs=1000, learning_rate=0.01)\n",
    "\n",
    "# Evaluate the neural network using the validation data\n",
    "validation_loss = neural_network.evaluate(X_val, y_val)\n",
    "print(f\"Validation Loss: {validation_loss}\")\n",
    "\n",
    "# Print the parameters of the neural network\n",
    "neural_network.print_parameters()\n",
    "\n",
    "# Evaluate the neural network using the testing data\n",
    "test_loss = neural_network.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "\n",
    "# Predict the target attribute for the testing data\n",
    "predictions = neural_network.predict(X_test)\n",
    "print(predictions)\n",
    "\n",
    "# Evaluate the model using accuracy, precision, recall, and F1-score\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "eval_accuracy = evaluation_metric.accuracy_score(y_test, predictions)\n",
    "\n",
    "precision = precision_score(y_test, predictions, average='weighted')\n",
    "eval_precision = evaluation_metric.precision_score(y_test, predictions, positive_label=1)\n",
    "\n",
    "recall = recall_score(y_test, predictions, average='weighted')\n",
    "eval_recall = evaluation_metric.recall_score(y_test, predictions, positive_label=1)\n",
    "\n",
    "f1 = f1_score(y_test, predictions, average='weighted')\n",
    "eval_f1 = evaluation_metric.f1_score(y_test, predictions, positive_label=1)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Eval Accuracy: {eval_accuracy:.2f}\")\n",
    "\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Eval Precision: {eval_precision:.2f}\")\n",
    "\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"Eval Recall: {eval_recall:.2f}\")\n",
    "\n",
    "print(f\"F1-score: {f1:.2f}\")\n",
    "print(f\"Eval F1-score: {eval_f1:.2f}\")  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Spécifiez le nom de la colonne cible\n",
    "target_attribute = \"Class\"\n",
    "\n",
    "# Divisez les données en ensembles d'entraînement, de validation et de test\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = neural_split_data(\n",
    "    data, target_attribute)\n",
    "\n",
    "test_net = NeuralNetwork(architecture=[14, 8, 4], activation='relu',X_train=X_train,y_train=y_train,X_test=X_test,y_test=y_test,learning_rate=0.01,epoch=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_models(X_train, y_train, X_val, y_val, architectures, activations, learning_rate=0.01, epochs=100, patience=4, batch_size=4):\n",
    "    \"\"\"\n",
    "    Train multiple neural network models with specified architectures and activations.\n",
    "\n",
    "    Parameters:\n",
    "    - X_train (np.array): Training data.\n",
    "    - y_train (np.array): Training labels.\n",
    "    - X_val (np.array): Validation data.\n",
    "    - y_val (np.array): Validation labels.\n",
    "    - architectures (list of lists): List of architectures (list of integers) to train.\n",
    "    - activations (list of str): List of activation functions to use ('tanh' and 'relu').\n",
    "    - learning_rate (float): Learning rate for training.\n",
    "    - epochs (int): Number of epochs to train for.\n",
    "    - patience (int): Patience for early stopping.\n",
    "    - batch_size (int): Size of mini-batch for training.\n",
    "\n",
    "    Returns:\n",
    "    - dict: Dictionary containing trained models for each architecture and activation function.\n",
    "    \"\"\"\n",
    "    models = {}\n",
    "\n",
    "    # Train models for each architecture and activation function\n",
    "    for activation in activations:\n",
    "        for architecture in architectures:\n",
    "            # Create neural network model\n",
    "            model = NeuralNetwork(architecture, activation)\n",
    "\n",
    "            # Train the model\n",
    "            model.train(X_train, y_train, X_val, y_val, learning_rate=learning_rate,\n",
    "                        epochs=epochs, patience=patience, batch_size=batch_size)\n",
    "\n",
    "            # Store the trained model\n",
    "            models[f\"{activation}_{architecture}\"] = model\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "architectures = [(14, 10, 8, 6, 4), (14, 10, 8, 4, 4), (14, 6, 4, 4)]\n",
    "activations = [\"tanh\", \"relu\"]\n",
    "models = train_models(X_train, y_train, X_val, y_val, architectures, activations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(models, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate trained models on the test data.\n",
    "\n",
    "    Parameters:\n",
    "    - models (dict): Dictionary containing trained models.\n",
    "    - X_test (np.array): Test data.\n",
    "    - y_test (np.array): Test labels.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Dictionary containing predictions and evaluation metrics for each model.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Evaluate each model\n",
    "    for model_name, model in models.items():\n",
    "        # Predict the test data\n",
    "        predictions = model.predict(X_test)\n",
    "        \n",
    "        # Calculate loss (or other evaluation metrics)\n",
    "        \n",
    "        loss = model.calculate_loss(X_test, y_test)\n",
    "\n",
    "        accuracy = np.mean(predictions == y_test)\n",
    "\n",
    "        \n",
    "        # Store results\n",
    "        results[model_name] = {\n",
    "            \"predictions\": predictions,\n",
    "            \"loss\": loss,\n",
    "            \"accuracy\": accuracy\n",
    "        }\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_models(models, X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spécifiez le nom de la colonne cible\n",
    "target_attribute = \"Class\"\n",
    "\n",
    "# Divisez les données en ensembles d'entraînement, de validation et de test\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = neural_split_data(data, target_attribute)\n",
    "\n",
    "\n",
    "# Liste des architectures à tester\n",
    "architectures = [(14, 10, 8, 6, 4)]\n",
    "\n",
    "# Fonction d'activation à tester\n",
    "activation = 'tanh'  # Utilisez 'tanh' ou 'relu'\n",
    "\n",
    "neural_network = NeuralNetwork(architecture=architectures[0])\n",
    "neural_network.train(X_train, y_train, X_val, y_val, learning_rate=0.01, epochs=50, patience=4, batch_size=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "data = pd.read_csv('test_data.csv')\n",
    "\n",
    "# Séparer les features et les labels\n",
    "X = data.drop('Label', axis=1)\n",
    "y = data['Label']\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le réseau de neurones\n",
    "nn = NeuralNetwork(architecture=[(14, 10, 8, 6, 4)], activation='relu')  # Architecture avec 3 couches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner le réseau\n",
    "nn.train(X_train, y_train, X_test, y_test, learning_rate=0.01, epochs=100, batch_size=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédire les labels sur l'ensemble de test\n",
    "predictions = nn.predict(X_test)  # Assurez-vous que les dimensions correspondent aux attentes de votre classe\n",
    "# Calculer les métriques de performance\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "report = classification_report(y_test, predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
